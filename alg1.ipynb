{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from deepface import DeepFace\n",
    "from deepface.commons import functions\n",
    "\n",
    "import lpips_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 1: Ensemble attack training procedure\n",
    "Inputs:\n",
    "- Victim Models (F)\n",
    "- Image Dataset (X)\n",
    "\n",
    "Outputs:\n",
    "- Perturbation Engine (g_theta)\n",
    "\n",
    "HyperParams:\n",
    "- Learning rate (alpha)\n",
    "- L_inf bound (epsilon)\n",
    "- Lpips loss coefficient (lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Victim Models (F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_models_labels = [\n",
    "  \"VGG-Face\", \n",
    "  \"Facenet\", \n",
    "  \"Facenet512\", \n",
    "  \"OpenFace\", \n",
    "  \"DeepFace\", \n",
    "  \"DeepID\", \n",
    "  \"ArcFace\", \n",
    "  \"SFace\"\n",
    "]\n",
    "\n",
    "F = set()\n",
    "\n",
    "for model_name in victim_models_labels:\n",
    "  F.add((DeepFace.build_model(model_name=model_name).model, functions.find_target_size(model_name)))\n",
    "  \n",
    "print(len(F))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Dataset (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, info = tfds.load('lfw',\n",
    "                      with_info=True,\n",
    "                      download=True,\n",
    "                      as_supervised=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = tf.Variable(0.2, trainable=False, name='alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = tf.Variable(0.5, trainable=False, name='epsilon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = tf.Variable(0.2, trainable=False, name='lambda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialized ATN ($N_{theta}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(input_size=(128,128,3), n_filters=32, n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Noise\n",
    "$$ x_{adv} \\leftarrow clip_{[0,1]}(x + \\epsilon \\cdot \\tanh(N_\\theta(x))) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addAdversarialNoise(x, eps, atn, training=True):\n",
    "  xadv = atn(x, training=training)\n",
    "  xadv = tf.tanh(xadv)\n",
    "  xadv = tf.multiply(eps, xadv)\n",
    "  xadv = tf.add(x, xadv)\n",
    "  xadv = tf.clip_by_value(xadv, 0, 1)\n",
    "  return xadv\n",
    "  # return tf.clip_by_value(tf.add(x, tf.multiply(eps, tf.tanh(atn(x)))), 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings Loss\n",
    "$$\n",
    "loss \\leftarrow \\dfrac{1}{\\left\\|\\mathbb{F}\\right\\|} \\sum^{\\mathbb{F}}_{f} - \\dfrac{f(x) \\cdot f(x_{adv})} {\\left\\| f(x)\\right\\|_{2}\\left\\| f(x_{adv})\\right\\|_{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fCosineDistance(x, x_adv, f):\n",
    "  emb_t = f(x)\n",
    "  emb_adv = f(x_adv)\n",
    "  dist = tf.keras.losses.cosine_similarity(emb_t, emb_adv, axis=1)\n",
    "  dist = tf.negative(dist)\n",
    "  return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLoss(x, x_adv, loss, F):\n",
    "  N = len(F)\n",
    "  for f in F:\n",
    "    model = f[0]\n",
    "    in_shape = f[1]\n",
    "    #TODO: convert to right shape\n",
    "    loss = tf.add(loss, fCosineDistance(model, x, x_adv))\n",
    "  loss = tf.divide(loss, N)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptual Loss ($L_{pips}$)\n",
    "$$\n",
    "loss \\leftarrow loss + \\lambda L_{pips}(x_{adv}, x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LpipsLoss(x, x_adv, loss, lda):\n",
    "  dist = lpips_tf.lpips(x_adv, x, model='net-lin', net='alex')\n",
    "  dist = tf.multiply(lda, dist)\n",
    "  loss = tf.add(loss, dist)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atnLoss(x, x_adv, F, lda):\n",
    "  loss = tf.Variable(0, trainable=False, name='loss')\n",
    "  loss = FLoss(x, x_adv, loss, F)\n",
    "  loss = LpipsLoss(x, x_adv, loss, lda)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, F, model, optimizer, eps, lda):\n",
    "  for epoch in range(epoch):\n",
    "    print(\"\\nEpoch: %d\" % (epoch,))\n",
    "    for step, (x_batch) in enumerate(X):\n",
    "      # Open GradientTape to record ops run during forward pass for auto-differentiation\n",
    "      with tf.GradientTape() as tape:\n",
    "        # Forward pass of layer.\n",
    "        # Ops applied recorded on GradientTape\n",
    "        x_adv = addAdversarialNoise(x_batch, eps, model, True)\n",
    "        loss = atnLoss(x_batch, x_adv, F, lda)\n",
    "      \n",
    "      # Use gradient tape to retrieve grads of trainable variables wrt loss\n",
    "      grads = tape.gradient(loss, model.trainable_weights)\n",
    "      \n",
    "      # Gradient descent, update variables to minimize loss.\n",
    "      optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "      \n",
    "      if step % 200 == 0:\n",
    "        print(\n",
    "          \"Training loss (for one batch) at step %d: %.4f\"\n",
    "          % (step, float(loss))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=atnLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import AuraMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AuraMask(32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build((None, 512,512,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class FaceEmbeddingsEnum(Enum):\n",
    "  VGGFACE = \"VGG-Face\"\n",
    "  FACENET = \"Facenet\"\n",
    "  FACENET512 = \"Facenet512\"\n",
    "  OPENFACE = \"OpenFace\"\n",
    "  DEEPFACE = \"DeepFace\"\n",
    "  DEEPID = \"DeepID\"\n",
    "  ARCFACE = \"ArcFace\"\n",
    "  SFACE = \"SFace\"\n",
    "  def get_model(self):\n",
    "    return DeepFace.build_model(model_name=self.value).model\n",
    "  def get_target_size(self):\n",
    "    return functions.find_target_size(model_name=self.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_F(targets: list[FaceEmbeddingsEnum]) -> set[(tf.Model, tuple)]:\n",
    "  F = set()\n",
    "  for model_label in targets:\n",
    "    F.add(\n",
    "      (\n",
    "        model_label.get_model(),\n",
    "        model_label.get_target_size(),\n",
    "      )\n",
    "    )\n",
    "  return F"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
